{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/KristoferLintonReid/hgsoc-prognosis-CTradiomics/blob/main/examples/nnunet_inference.ipynb)\n",
                "\n",
                "# nnUNet Inference and Dice Score Calculation\n",
                "\n",
                "This notebook demonstrates how to run nnUNet inference and calculate the Dice score.\n",
                "\n",
                "**Compatibility:**\n",
                "- **Local Machine (macOS/Linux):** Runs with your local environment.\n",
                "- **Google Colab:** Automatically installs dependencies and enables GPU acceleration.\n",
                "\n",
                "**Prerequisites:**\n",
                "- **Model:** A trained nnUNet model folder (e.g., `Task001_OVARIAN`).\n",
                "- **Input Data:** An image file (`.nii.gz`) to segment.\n",
                "- **Ground Truth:** (Optional) A segmentation file for Dice calculation.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import shutil\n",
                "import subprocess\n",
                "import sys\n",
                "import numpy as np\n",
                "\n",
                "# --- Environment Detection ---\n",
                "try:\n",
                "    from google.colab import drive\n",
                "    IS_COLAB = True\n",
                "    print(\"Detected Google Colab environment.\")\n",
                "except ImportError:\n",
                "    IS_COLAB = False\n",
                "    print(\"Detected Local environment.\")\n",
                "\n",
                "# --- Colab Setup ---\n",
                "if IS_COLAB:\n",
                "    print(\"Installing dependencies for Colab...\")\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nnunet\", \"nibabel\", \"numpy<2\"])\n",
                "    \n",
                "    print(\"Mounting Google Drive...\")\n",
                "    drive.mount('/content/drive')\n",
                "    \n",
                "    # Define Colab-specific paths\n",
                "    # NOTE: Update these paths to match your Drive structure if needed\n",
                "    base_dir = \"/content/drive/MyDrive/hgsoc-prognosis-CTradiomics/examples\"\n",
                "    if not os.path.exists(base_dir):\n",
                "        print(f\"Warning: Base directory {base_dir} does not exist. Using local workspace.\")\n",
                "        base_dir = \"/content\"\n",
                "else:\n",
                "    # Local paths\n",
                "    base_dir = os.path.abspath(\".\")\n",
                "\n",
                "print(f\"Working Directory: {base_dir}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nibabel as nib\n",
                "import torch\n",
                "\n",
                "# --- Configuration ---\n",
                "# Paths for Model and Data\n",
                "local_results_folder = os.path.join(base_dir, \"nnunet_trained_models\")\n",
                "\n",
                "# Input/Output Directories (Temporary)\n",
                "temp_input_dir = os.path.join(base_dir, \"temp_inference_input\")\n",
                "temp_output_dir = os.path.join(base_dir, \"temp_inference_output\")\n",
                "\n",
                "os.makedirs(temp_input_dir, exist_ok=True)\n",
                "os.makedirs(temp_output_dir, exist_ok=True)\n",
                "\n",
                "# Case Configuration\n",
                "case_identifier = \"Test_Case\"\n",
                "input_image_name = \"tcga-09-0367.nii.gz\"\n",
                "ground_truth_name = \"tcga-09-0367-seg.nii.gz\"\n",
                "\n",
                "input_image_path = os.path.join(base_dir, input_image_name)\n",
                "ground_truth_path = os.path.join(base_dir, ground_truth_name)\n",
                "formatted_input_path = os.path.join(temp_input_dir, f\"{case_identifier}_0000.nii.gz\")\n",
                "\n",
                "# --- File Verification ---\n",
                "if not os.path.exists(input_image_path):\n",
                "    print(f\"ERROR: Input file '{input_image_name}' not found in {base_dir}.\")\n",
                "    if IS_COLAB:\n",
                "        print(\"Please upload the file to your Google Drive folder or the Colab workspace.\")\n",
                "else:\n",
                "    print(f\"Found input image: {input_image_path}\")\n",
                "    shutil.copy(input_image_path, formatted_input_path)\n",
                "\n",
                "# Check for Model\n",
                "model_check_path = os.path.join(local_results_folder, \"nnUNet\", \"3d_fullres\", \"Task001_OVARIAN\")\n",
                "if not os.path.exists(model_check_path):\n",
                "    print(f\"WARNING: Model folder not found at {model_check_path}\")\n",
                "    if IS_COLAB:\n",
                "        print(\"Please ensure your Google Drive paths are correct or upload the 'nnunet_trained_models' folder.\")\n",
                "else:\n",
                "    print(\"Model folder found.\")\n",
                "\n",
                "# Check GPU\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU Detected: {torch.cuda.get_device_name(0)}\")\n",
                "    use_gpu = True\n",
                "else:\n",
                "    print(\"No GPU detected. Using CPU (this will be slower).\")\n",
                "    use_gpu = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Set Environment Variables ---\n",
                "os.environ[\"RESULTS_FOLDER\"] = local_results_folder\n",
                "os.environ[\"nnUNet_raw_data_base\"] = os.path.join(local_results_folder, \"nnUNet_raw_data_base\")\n",
                "os.environ[\"nnUNet_preprocessed\"] = os.path.join(local_results_folder, \"nnUNet_preprocessed\")\n",
                "\n",
                "print(\"Environment variables set.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Run Inference ---\n",
                "task_id = \"001\"\n",
                "config = \"3d_fullres\"\n",
                "\n",
                "# Construct Command\n",
                "cmd = [\n",
                "    \"nnUNet_predict\",\n",
                "    \"-i\", temp_input_dir,\n",
                "    \"-o\", temp_output_dir,\n",
                "    \"-t\", task_id,\n",
                "    \"-m\", config\n",
                "]\n",
                "\n",
                "# Optimization Flags\n",
                "if not use_gpu:\n",
                "    # CPU Optimizations (Fast Mode)\n",
                "    print(\"Optimizing for CPU: Single fold, No TTA.\")\n",
                "    cmd.extend([\"-f\", \"0\", \"--disable_tta\"])\n",
                "else:\n",
                "    # GPU: Options\n",
                "    # Uncomment detection to use full ensemble if desired, but single fold is usually sufficient for demos\n",
                "    print(\"GPU enabled. Using standard inference (Fold 0 + TTA Disabled for speed, remove flags for full quality).\")\n",
                "    # You can remove these flags on GPU if you want max accuracy (but slower)\n",
                "    cmd.extend([\"-f\", \"0\", \"--disable_tta\"])\n",
                "\n",
                "print(f\"Running command: {' '.join(cmd)}\")\n",
                "\n",
                "try:\n",
                "    if os.path.exists(formatted_input_path) and os.path.exists(model_check_path):\n",
                "        # Stream output\n",
                "        process = subprocess.Popen(\n",
                "            cmd, \n",
                "            env=os.environ.copy(), \n",
                "            stdout=subprocess.PIPE, \n",
                "            stderr=subprocess.STDOUT,\n",
                "            text=True,\n",
                "            bufsize=1\n",
                "        )\n",
                "        \n",
                "        print(\"\\n--- Inference Output Stream ---\")\n",
                "        for line in iter(process.stdout.readline, ''):\n",
                "            print(line, end='')\n",
                "        \n",
                "        process.stdout.close()\n",
                "        return_code = process.wait()\n",
                "        \n",
                "        if return_code == 0:\n",
                "            print(\"\\nInference completed successfully.\")\n",
                "        else:\n",
                "            print(f\"\\nError: Process finished with exit code {return_code}\")\n",
                "    else:\n",
                "        print(\"Skipping inference: missing input file or model folder.\")\n",
                "except Exception as e:\n",
                "    print(f\"Error during execution: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Calculate Dice Score ---\n",
                "def dice_coefficient(y_true, y_pred):\n",
                "    smooth = 1e-6\n",
                "    y_true_f = y_true.flatten()\n",
                "    y_pred_f = y_pred.flatten()\n",
                "    intersection = np.sum(y_true_f * y_pred_f)\n",
                "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
                "\n",
                "if not os.path.exists(ground_truth_path):\n",
                "    print(f\"Ground truth file '{ground_truth_name}' not found.\")\n",
                "else:\n",
                "    print(f\"Loading Ground Truth from {ground_truth_path}...\")\n",
                "    gt_nii = nib.load(ground_truth_path)\n",
                "    gt_data = gt_nii.get_fdata()\n",
                "\n",
                "    prediction_filename = f\"{case_identifier}.nii.gz\"\n",
                "    prediction_path = os.path.join(temp_output_dir, prediction_filename)\n",
                "\n",
                "    if not os.path.exists(prediction_path):\n",
                "        print(f\"Error: Prediction file not found at {prediction_path}\")\n",
                "    else:\n",
                "        print(f\"Loading Prediction from {prediction_path}...\")\n",
                "        pred_nii = nib.load(prediction_path)\n",
                "        pred_data = pred_nii.get_fdata()\n",
                "\n",
                "        if gt_data.shape != pred_data.shape:\n",
                "            print(f\"Warning: Shape mismatch! GT: {gt_data.shape}, Pred: {pred_data.shape}\")\n",
                "        else:\n",
                "            unique_labels = np.unique(gt_data)\n",
                "            print(f\"Unique labels in GT: {unique_labels}\")\n",
                "\n",
                "            for label in unique_labels:\n",
                "                if label == 0: continue \n",
                "                \n",
                "                gt_binary = (gt_data == label).astype(float)\n",
                "                pred_binary = (pred_data == label).astype(float)\n",
                "                \n",
                "                score = dice_coefficient(gt_binary, pred_binary)\n",
                "                print(f\"Dice Score for Label {int(label)}: {score:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Cleanup (Optional) ---\n",
                "# shutil.rmtree(temp_input_dir)\n",
                "# shutil.rmtree(temp_output_dir)\n",
                "# print(\"Temporary directories removed.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "nnUNet (Conda)",
            "language": "python",
            "name": "nnunetv1"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}